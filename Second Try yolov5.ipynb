{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAuz6F0Fee-Y",
        "outputId": "4ca22748-f616-4abb-ffe8-2d943263d140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "8189\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# !unzip \"/content/drive/My Drive/102flowers.zip\" -d \"/content/drive/My Drive/\"\n",
        "\n",
        "\n",
        "dataset_path = \"/content/drive/My Drive/jpg\"\n",
        "image_filenames = os.listdir(dataset_path)\n",
        "image_filenames.sort()\n",
        "print(len(image_filenames))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import cv2, numpy as np\n",
        "mat = scipy.io.loadmat('/content/imagelabels.mat')\n",
        "labels=mat[\"labels\"][0]\n",
        "# for i in labels:\n",
        "#   print(i)\n",
        "print(len(labels))\n",
        "print(type(str(labels[0],'UTF-8')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAMEpanbk2Qt",
        "outputId": "8f19d578-5dcf-4946-aab5-cccd6204d6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8189\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip install -r requirements.txt\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQcQCKYoK9KD",
        "outputId": "a21d89e7-8f26-4a59-a5e3-c5ec8d40dbca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15996, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 15996 (delta 100), reused 131 (delta 85), pack-reused 15831\u001b[K\n",
            "Receiving objects: 100% (15996/15996), 14.58 MiB | 35.22 MiB/s, done.\n",
            "Resolving deltas: 100% (10974/10974), done.\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvQ-KKugLV-C",
        "outputId": "82c2c29a-f9dd-49c1-da2f-0fb675802fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics"
      ],
      "metadata": {
        "id": "rVLVQb31L1sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
      ],
      "metadata": {
        "id": "F64xUhRqLxYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "# Remove the last layer from the model\n",
        "# model.model[-1] = nn.Identity()\n",
        "sequential=list(list(model.model.children())[0].children())[0][:-1]\n",
        "model_without_last_layer = nn.Sequential(sequential)"
      ],
      "metadata": {
        "id": "vaNR2indMqoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequential)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb7gcAR8iRqs",
        "outputId": "c5f703df-5342-4dc7-835a-6f0f6982c508"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (1): Conv(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (2): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (3): Conv(\n",
            "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (4): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (5): Conv(\n",
            "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (6): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (7): Conv(\n",
            "    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (8): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (9): SPPF(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (10): Conv(\n",
            "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (11): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (12): Concat()\n",
            "  (13): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (14): Conv(\n",
            "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (15): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (16): Concat()\n",
            "  (17): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (18): Conv(\n",
            "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (19): Concat()\n",
            "  (20): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (21): Conv(\n",
            "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (22): Concat()\n",
            "  (23): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(list(list(model.model.children())[0].children())[0])\n",
        "i=0\n",
        "for layer in model_without_last_layer.children():\n",
        "    print(i,layer)\n",
        "    i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otRkdX3OS8NI",
        "outputId": "2aae147a-b15e-47cd-c1f8-f8e76e3b9fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Sequential(\n",
            "  (0): Conv(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (1): Conv(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (2): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (3): Conv(\n",
            "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (4): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (5): Conv(\n",
            "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (6): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (7): Conv(\n",
            "    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (8): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (9): SPPF(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (10): Conv(\n",
            "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (11): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (12): Concat()\n",
            "  (13): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (14): Conv(\n",
            "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (15): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (16): Concat()\n",
            "  (17): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (18): Conv(\n",
            "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (19): Concat()\n",
            "  (20): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (21): Conv(\n",
            "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (22): Concat()\n",
            "  (23): C3(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv3): Conv(\n",
            "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "SAOklexeNfoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = os.path.join(dataset_path, image_filenames[0])\n",
        "image = Image.open(img_path)\n",
        "\n",
        "# Preprocess the image\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    output = model_without_last_layer(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "0TWGl-giNloD",
        "outputId": "51db18b7-3588-4e52-aa9c-7b082fcdc91b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-e18a9358c97f>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_without_last_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bsB_FI_SBQM",
        "outputId": "8cb38b01-9867-428e-fc36-2a94d4c82a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.03981,  0.00557, -0.04581,  ..., -1.67266, -1.63841, -1.62129],\n",
            "          [ 0.05694,  0.02269, -0.02868,  ..., -1.68979, -1.67266, -1.65554],\n",
            "          [ 0.10831,  0.07406,  0.00557,  ..., -1.74116, -1.70691, -1.70691],\n",
            "          ...,\n",
            "          [ 0.45081,  0.38231,  0.27956,  ..., -0.91917, -0.91917, -0.90205],\n",
            "          [ 0.48506,  0.39943,  0.31381,  ..., -0.91917, -0.91917, -0.90205],\n",
            "          [ 0.50218,  0.43368,  0.33094,  ..., -0.91917, -0.91917, -0.90205]],\n",
            "\n",
            "         [[ 0.06513,  0.03011, -0.02241,  ..., -1.54552, -1.51050, -1.49300],\n",
            "          [ 0.08263,  0.04762, -0.00490,  ..., -1.56303, -1.54552, -1.52801],\n",
            "          [ 0.13515,  0.10014,  0.03011,  ..., -1.61555, -1.58053, -1.58053],\n",
            "          ...,\n",
            "          [ 0.71289,  0.64286,  0.53782,  ..., -1.14286, -1.14286, -1.12535],\n",
            "          [ 0.74790,  0.66036,  0.57283,  ..., -1.14286, -1.14286, -1.12535],\n",
            "          [ 0.76541,  0.69538,  0.59034,  ..., -1.14286, -1.14286, -1.12535]],\n",
            "\n",
            "         [[-0.13124, -0.16610, -0.21839,  ..., -1.54301, -1.50815, -1.49072],\n",
            "          [-0.07895, -0.14867, -0.20096,  ..., -1.56044, -1.54301, -1.52558],\n",
            "          [-0.02667, -0.06152, -0.16610,  ..., -1.61272, -1.57786, -1.57786],\n",
            "          ...,\n",
            "          [ 0.21734,  0.14763,  0.02562,  ..., -1.21185, -1.21185, -1.19442],\n",
            "          [ 0.25220,  0.16505,  0.06048,  ..., -1.21185, -1.21185, -1.19442],\n",
            "          [ 0.26963,  0.19991,  0.07791,  ..., -1.21185, -1.21185, -1.19442]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = []\n",
        "\n",
        "for image_name in image_filenames:\n",
        "    img_path = os.path.join(dataset_path, image_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = torch.from_numpy(img / 255.0).permute(2, 0, 1).unsqueeze(0).float()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        features.append(model.forward_backbone(img).squeeze().cpu().numpy())\n"
      ],
      "metadata": {
        "id": "a3GdM9QaJ7q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZT6_TDMoJ7ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6fXwQKtJ7c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D9-ALU0xJ7ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6UV3hMeJ7Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czx9kfPpJ7Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eBBKlV1ZJ7Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQJ_ASiHJ7Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uf0lNFNhJ7H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5zCBak6J7Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "Tot1BNsmkQDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_images_filenames, val_images_filenames, train_labels_filenames, val_labels_filenames = train_test_split(\n",
        "    image_filenames, labels, train_size=0.5, random_state=42\n",
        ")\n",
        "val_images_filenames, test_images_filenames, val_labels_filenames, test_labels_filenames = train_test_split(\n",
        "    val_images_filenames, val_labels_filenames, test_size=0.5, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "NA6CRUUekbVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=[]\n",
        "for filename in train_images_filenames:\n",
        "  images.append(preprocess_image(os.path.join(\"/content/drive/My Drive/jpg\",filename)))"
      ],
      "metadata": {
        "id": "2fWUSeJ9lDUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Image\n",
        "im =\"/content/drive/My Drive/jpg/image_00001.jpg\" #'https://ultralytics.com/images/zidane.jpg'\n",
        "\n",
        "# Inference\n",
        "results = model(im)\n",
        "print(type(results))\n",
        "\n",
        "results.pandas().xyxy[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "MqUFPrulZ47U",
        "outputId": "ac57bee0-bad1-45fd-a74c-e44349705a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement \"gitpython>=3.1.30\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 55.9 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 236.9 MB/s eta 0:00:00\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.31 smmap-5.0.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 2023-6-23 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|██████████| 14.1M/14.1M [00:00<00:00, 314MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-aaf2afc82e25>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Remove the last layer from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DetectMultiBackend' object does not support item assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "dg38oB2bwh-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import utils\n",
        "# from utils.general import non_max_suppression\n",
        "from yolov5.utils.general import non_max_suppression"
      ],
      "metadata": {
        "id": "fP-3wFQFxge_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def yolo_classify(image):\n",
        "#     model.eval()\n",
        "#     if torch.cuda.is_available():\n",
        "#         image = image.cuda()\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(image)\n",
        "#         # Process the outputs and extract bounding box information\n",
        "#         # ...\n",
        "#     return outputs\n"
      ],
      "metadata": {
        "id": "FVGtFddMkS6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "def yolo_classify(image):\n",
        "    model.eval()\n",
        "    if torch.cuda.is_available():\n",
        "        image = image.cuda()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "\n",
        "        # Process the outputs and extract bounding box information\n",
        "        boxes = []\n",
        "        class_labels = []\n",
        "        scores = []\n",
        "\n",
        "        # Iterate over each output\n",
        "        for output in outputs:\n",
        "            # Extract class probabilities, bounding box coordinates, and confidence scores\n",
        "            class_probs = output[..., 5:]\n",
        "            pred_scores, pred_labels = torch.max(class_probs, dim=-1)\n",
        "            pred_boxes = output[..., :4]\n",
        "\n",
        "            # Apply non-maximum suppression to filter out overlapping bounding boxes\n",
        "            keep = torchvision.ops.boxes.batched_nms(pred_boxes, pred_scores, pred_labels, iou_threshold=0.5)\n",
        "\n",
        "            # Append the filtered bounding boxes, class labels, and scores to the respective lists\n",
        "            boxes.append(pred_boxes[keep])\n",
        "            class_labels.append(pred_labels[keep])\n",
        "            scores.append(pred_scores[keep])\n",
        "\n",
        "    return boxes, class_labels, scores\n"
      ],
      "metadata": {
        "id": "4tsDxk41x5_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxes, class_labels, scores=yolo_classify(images[0])\n",
        "# for i in class_labels[0]:\n",
        "#   print(class_labels[0][i])\n",
        "# print(class_labels[0][0])"
      ],
      "metadata": {
        "id": "Re2OBKIEv255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "ed87be17-f637-4d28-ef21-03176bddb93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-2590defe2e04>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myolo_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# for i in class_labels[0]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#   print(class_labels[0][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(class_labels[0][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-5e70fd1ba67a>\u001b[0m in \u001b[0;36myolo_classify\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Apply non-maximum suppression to filter out overlapping bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatched_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Append the filtered bounding boxes, class labels, and scores to the respective lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py\u001b[0m in \u001b[0;36mbatched_nms\u001b[0;34m(boxes, scores, idxs, iou_threshold)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# https://github.com/pytorch/vision/issues/1311#issuecomment-781329339\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_batched_nms_vanilla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_batched_nms_coordinate_trick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0;31m# Not tracing, don't do anything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mcompiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__original_fn\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py\u001b[0m in \u001b[0;36m_batched_nms_vanilla\u001b[0;34m(boxes, scores, idxs, iou_threshold)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclass_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mcurr_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclass_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mcurr_keep_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mkeep_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_keep_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mkeep_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/boxes.py\u001b[0m in \u001b[0;36mnms\u001b[0;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0m_assert_has_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: boxes should be a 2d tensor, got 3D"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg_classify(image):\n",
        "    vgg_model.eval()\n",
        "    if torch.cuda.is_available():\n",
        "        image = image.cuda()\n",
        "    with torch.no_grad():\n",
        "        outputs = vgg_model(image)\n",
        "        # Process the outputs and obtain class probabilities\n",
        "        class_probs = torch.softmax(outputs, dim=1)\n",
        "    return class_probs\n"
      ],
      "metadata": {
        "id": "eXn7iMMHkX0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vgg_classify(images[0]))"
      ],
      "metadata": {
        "id": "uLAxDo-_5q-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def apply_nms(boxes, scores, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Apply non-maximum suppression (NMS) to filter bounding boxes.\n",
        "    \"\"\"\n",
        "    # Sort boxes by their scores in descending order\n",
        "    sorted_indices = np.argsort(scores)[::-1]\n",
        "    boxes = boxes[sorted_indices]\n",
        "    scores = scores[sorted_indices]\n",
        "\n",
        "    # Initialize an empty list to store the selected boxes\n",
        "    selected_boxes = []\n",
        "\n",
        "    while len(boxes) > 0:\n",
        "        # Select the bounding box with the highest score\n",
        "        selected_box = boxes[0]\n",
        "        selected_boxes.append(selected_box)\n",
        "\n",
        "        # Compute the IoU (Intersection over Union) between the selected box and the remaining boxes\n",
        "        iou = calculate_iou(selected_box, boxes[1:])\n",
        "\n",
        "        # Filter out the boxes with IoU above the threshold\n",
        "        mask = iou <= threshold\n",
        "        boxes = boxes[1:][mask]\n",
        "        scores = scores[1:][mask]\n",
        "\n",
        "    return selected_boxes\n",
        "\n",
        "def calculate_iou(box, boxes):\n",
        "    \"\"\"\n",
        "    Calculate the IoU (Intersection over Union) between a box and a list of boxes.\n",
        "    \"\"\"\n",
        "    # Calculate the intersection coordinates\n",
        "    x1 = np.maximum(box[0], boxes[:, 0])\n",
        "    y1 = np.maximum(box[1], boxes[:, 1])\n",
        "    x2 = np.minimum(box[2], boxes[:, 2])\n",
        "    y2 = np.minimum(box[3], boxes[:, 3])\n",
        "\n",
        "    # Calculate the areas of the intersection and the union\n",
        "    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n",
        "    union = (box[2] - box[0]) * (box[3] - box[1]) + (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1]) - intersection\n",
        "\n",
        "    # Calculate the IoU\n",
        "    iou = intersection / union\n",
        "\n",
        "    return iou\n",
        "\n",
        "def classify_image(image):\n",
        "    yolo_boxes, _, _ = yolo_classify(image)\n",
        "    vgg_probs = vgg_classify(image)\n",
        "\n",
        "    # Process the outputs and obtain probabilistic predictions\n",
        "    predictions = []\n",
        "\n",
        "    # Iterate over each bounding box from YOLOv5\n",
        "    for boxes in yolo_boxes:\n",
        "        # Apply NMS to filter bounding boxes\n",
        "        filtered_boxes = apply_nms(boxes[:, :4], boxes[:, 4])\n",
        "\n",
        "        # Iterate over each filtered bounding box\n",
        "        for box in filtered_boxes:\n",
        "            # Extract the coordinates of the bounding box\n",
        "            ymin, xmin, ymax, xmax = box\n",
        "\n",
        "            # Crop the image based on the bounding box coordinates\n",
        "            cropped_image = image[:, :, int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "\n",
        "            # Classify the cropped image using the VGG model\n",
        "            vgg_probs_crop = vgg_classify(cropped_image)\n",
        "\n",
        "            # Combine the YOLOv5 and VGG predictions\n",
        "            combined_probs = vgg_probs * vgg_probs_crop\n",
        "\n",
        "            # Append the combined probabilities to the predictions list\n",
        "            predictions.append(combined_probs)\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "SmwlKmfZ6LtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classify_image(images[0]))"
      ],
      "metadata": {
        "id": "vt--kFHK6s4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKQ_pRn1OXix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_ZKqJbwOXYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhCcq3mmOXUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NE6vvHxDOXRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lbxEFqDaOXOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=[]\n",
        "import scipy.io\n",
        "import cv2, numpy as np\n",
        "mat = scipy.io.loadmat('/content/imagelabels.mat')\n",
        "labels=mat[\"labels\"][0]\n",
        "\n",
        "for i in range(8189):\n",
        "  dataset.append([image_filenames[i],labels[i]])\n",
        "dataset = np.asarray(dataset)\n",
        "\n",
        "cur_dir_path = os.path.join(\"/content/drive/My Drive/dataset\")\n",
        "if not os.path.exists(cur_dir_path):\n",
        "    os.mkdir(cur_dir_path)\n",
        "for i in range(1,103):\n",
        "    class_dir = os.path.join(\"/content/drive/My Drive/dataset\", str(i))\n",
        "    os.mkdir(class_dir)\n",
        "\n",
        "for label in dataset:\n",
        "    filename = str(label[0])\n",
        "    src = os.path.join(\"/content/drive/My Drive/jpg\",filename)\n",
        "    dst = os.path.join(\"/content/drive/My Drive/dataset\", label[1], src.split(os.sep)[-1])\n",
        "    shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "G9EDaMH3PAEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path= \"/content/drive/My Drive/dataset\""
      ],
      "metadata": {
        "id": "TPZ7lNQQiRkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import detection\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the dataset path\n",
        "\n",
        "# Define the transforms to apply to the dataset\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((416, 416)),  # Resize the images to fit the YOLOv5 input size\n",
        "    transforms.ToTensor()  # Convert the images to tensors\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = ImageFolder(dataset_path, transform=transforms)\n",
        "\n",
        "# Define the sizes for training, validation, and test sets\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(0.5 * dataset_size)\n",
        "val_size = int(0.25 * dataset_size)\n",
        "test_size = dataset_size - train_size - val_size\n",
        "\n",
        "# Split the dataset randomly into training, validation, and test sets\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create data loaders for each set\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# Load the pre-trained YOLOv5 model\n",
        "model = detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# Modify the model to adapt it to flower classification\n",
        "num_classes = len(dataset.classes)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = nn.Linear(in_features, num_classes)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Convert the labels to target boxes in [x_min, y_min, x_max, y_max] format\n",
        "        targets = []\n",
        "        for label in labels:\n",
        "            target = {'boxes': torch.zeros(1, 4), 'labels': label.unsqueeze(0)}\n",
        "            target['boxes'][0] = torch.tensor([0, 0, 1, 1])  # Placeholder values for target boxes\n",
        "            targets.append(target)\n",
        "\n",
        "        outputs = model(images, targets=targets)\n",
        "        loss = criterion(outputs[0]['labels'], labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs[0]['labels'], labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "_dTBFjzuOXA9",
        "outputId": "9815379e-bdec-4e54-b52d-b936ea68cc90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-19792d194e6c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"targets should not be none when in training mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_assert\u001b[0;34m(condition, message)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_assert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: targets should not be none when in training mode"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs[0]['labels'], 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        loss = criterion(outputs[0]['labels'], labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f} | Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "1CiCWURKrSn2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}